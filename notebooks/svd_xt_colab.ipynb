{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Stable Video Diffusion for Colab - v0.01\n",
        "This notebook generates videos of 1024x576 resolution with 25 frames in length using the Stability AI - Stable Video Diffusion model:\n",
        "\n",
        "https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt\n",
        "\n",
        "\n",
        "##Instructions\n",
        "Execute the cells in this notebook step by step.\n",
        "Do not run all the cells at once; you will need to restart the environment in step 2.\n",
        "\n",
        "*Tested on Nvidia Tesla T4*"
      ],
      "metadata": {
        "id": "ndKh-DSnGfWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1\n",
        "Check environment GPU. Minimun required Testla T4"
      ],
      "metadata": {
        "id": "B1GFFUpdIwy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzFFxcX6zaqf",
        "outputId": "bdf1a25a-4232-4c92-d686-67ac6fc9d410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 11:22:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2\n",
        "Clone the Stable Video Diffusion repository and **install requirements**.\n",
        "\n",
        "***IMPORTANT:*** After installing the requirements, you'll need to restart the environment to apply the changes. Simply follow the steps provided at the end of the execution.\n",
        "\n",
        "***NOTE:*** This is not the official repository; it's a fork of the official repository with minimal modifications to enable inference in half precision, aiming to minimize memory requirements."
      ],
      "metadata": {
        "id": "a7_ryFJ6J2ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b variations https://github.com/alvaromah/generative-models.git\n",
        "!pip install -r generative-models/requirements/pt2.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z21AUMS3z2wX",
        "outputId": "ba3b504f-30bb-4931-c318-d0653db77e57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'generative-models'...\n",
            "remote: Enumerating objects: 474, done.\u001b[K\n",
            "remote: Counting objects: 100% (313/313), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 474 (delta 186), reused 166 (delta 115), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (474/474), 40.54 MiB | 17.02 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "Collecting clip@ git+https://github.com/openai/CLIP.git (from -r generative-models/requirements/pt2.txt (line 3))\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-p4du2uky/clip_2363e44f997b40469e202abf57c0c941\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-p4du2uky/clip_2363e44f997b40469e202abf57c0c941\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting black==23.7.0 (from -r generative-models/requirements/pt2.txt (line 1))\n",
            "  Downloading black-23.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==5.1.0 (from -r generative-models/requirements/pt2.txt (line 2))\n",
            "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.1 (from -r generative-models/requirements/pt2.txt (line 4))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale>=0.4.13 (from -r generative-models/requirements/pt2.txt (line 5))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire>=0.5.0 (from -r generative-models/requirements/pt2.txt (line 6))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 7)) (2023.6.0)\n",
            "Collecting invisible-watermark>=0.2.0 (from -r generative-models/requirements/pt2.txt (line 8))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia==0.6.9 (from -r generative-models/requirements/pt2.txt (line 9))\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl (569 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m569.1/569.1 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=3.7.2 (from -r generative-models/requirements/pt2.txt (line 10))\n",
            "  Downloading matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 11)) (8.4.0)\n",
            "Collecting ninja>=1.11.1 (from -r generative-models/requirements/pt2.txt (line 12))\n",
            "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "Collecting numpy>=1.24.4 (from -r generative-models/requirements/pt2.txt (line 13))\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.3.0 (from -r generative-models/requirements/pt2.txt (line 14))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting open-clip-torch>=2.20.0 (from -r generative-models/requirements/pt2.txt (line 15))\n",
            "  Downloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.6.0.66 (from -r generative-models/requirements/pt2.txt (line 16))\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=2.0.3 (from -r generative-models/requirements/pt2.txt (line 17))\n",
            "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=9.5.0 (from -r generative-models/requirements/pt2.txt (line 18))\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pudb>=2022.1.3 (from -r generative-models/requirements/pt2.txt (line 19))\n",
            "  Downloading pudb-2023.1.tar.gz (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.3/224.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-lightning==2.0.1 (from -r generative-models/requirements/pt2.txt (line 20))\n",
            "  Downloading pytorch_lightning-2.0.1-py3-none-any.whl (716 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.4/716.4 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 21)) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 22)) (1.11.3)\n",
            "Collecting streamlit>=0.73.1 (from -r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardx==2.6 (from -r generative-models/requirements/pt2.txt (line 24))\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.2 (from -r generative-models/requirements/pt2.txt (line 25))\n",
            "  Downloading timm-0.9.11-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.12.1 (from -r generative-models/requirements/pt2.txt (line 26))\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 27)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 28)) (2.1.0+cu118)\n",
            "Collecting torchdata==0.6.1 (from -r generative-models/requirements/pt2.txt (line 29))\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=1.0.1 (from -r generative-models/requirements/pt2.txt (line 30))\n",
            "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 31)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 32)) (4.66.1)\n",
            "Collecting transformers==4.19.1 (from -r generative-models/requirements/pt2.txt (line 33))\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from -r generative-models/requirements/pt2.txt (line 34))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4 (from -r generative-models/requirements/pt2.txt (line 35))\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb>=0.15.6 (from -r generative-models/requirements/pt2.txt (line 36))\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webdataset>=0.2.33 (from -r generative-models/requirements/pt2.txt (line 37))\n",
            "  Downloading webdataset-0.2.79-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from -r generative-models/requirements/pt2.txt (line 38)) (0.41.3)\n",
            "Collecting xformers>=0.0.20 (from -r generative-models/requirements/pt2.txt (line 39))\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1)) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1)) (23.2)\n",
            "Collecting pathspec>=0.9.0 (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1))\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==23.7.0->-r generative-models/requirements/pt2.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==2.0.1->-r generative-models/requirements/pt2.txt (line 20)) (4.5.0)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning==2.0.1->-r generative-models/requirements/pt2.txt (line 20))\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardx==2.6->-r generative-models/requirements/pt2.txt (line 24)) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->-r generative-models/requirements/pt2.txt (line 29)) (2.31.0)\n",
            "Collecting torch>=2.0.1 (from -r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r generative-models/requirements/pt2.txt (line 33)) (0.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r generative-models/requirements/pt2.txt (line 33)) (2023.6.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->-r generative-models/requirements/pt2.txt (line 34)) (3.27.7)\n",
            "Collecting lit (from triton==2.0.0->-r generative-models/requirements/pt2.txt (line 34))\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (67.7.2)\n",
            "Collecting ftfy (from clip@ git+https://github.com/openai/CLIP.git->-r generative-models/requirements/pt2.txt (line 3))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.5.0->-r generative-models/requirements/pt2.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.5.0->-r generative-models/requirements/pt2.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark>=0.2.0->-r generative-models/requirements/pt2.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.2->-r generative-models/requirements/pt2.txt (line 10)) (2.8.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.3.0->-r generative-models/requirements/pt2.txt (line 14))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece (from open-clip-torch>=2.20.0->-r generative-models/requirements/pt2.txt (line 15))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->-r generative-models/requirements/pt2.txt (line 17)) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.3->-r generative-models/requirements/pt2.txt (line 17))\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urwid>=1.1.1 (from pudb>=2022.1.3->-r generative-models/requirements/pt2.txt (line 19))\n",
            "  Downloading urwid-2.2.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.4/274.4 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from pudb>=2022.1.3->-r generative-models/requirements/pt2.txt (line 19)) (2.16.1)\n",
            "Collecting jedi<1,>=0.18 (from pudb>=2022.1.3->-r generative-models/requirements/pt2.txt (line 19))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urwid_readline (from pudb>=2022.1.3->-r generative-models/requirements/pt2.txt (line 19))\n",
            "  Downloading urwid_readline-0.13.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (5.3.2)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (6.8.0)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (9.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.2->-r generative-models/requirements/pt2.txt (line 25)) (0.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio>=2.0.2 (from -r generative-models/requirements/pt2.txt (line 28))\n",
            "  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.15.2 (from -r generative-models/requirements/pt2.txt (line 31))\n",
            "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r generative-models/requirements/pt2.txt (line 36)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.15.6->-r generative-models/requirements/pt2.txt (line 36))\n",
            "  Downloading sentry_sdk-1.37.0-py2.py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.15.6->-r generative-models/requirements/pt2.txt (line 36))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.15.6->-r generative-models/requirements/pt2.txt (line 36))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.15.6->-r generative-models/requirements/pt2.txt (line 36)) (1.4.4)\n",
            "Collecting braceexpand (from webdataset>=0.2.33->-r generative-models/requirements/pt2.txt (line 37))\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.20 (from -r generative-models/requirements/pt2.txt (line 39))\n",
            "  Downloading xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.12.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (3.8.6)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi<1,>=0.18->pudb>=2022.1.3->-r generative-models/requirements/pt2.txt (line 19)) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r generative-models/requirements/pt2.txt (line 29)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r generative-models/requirements/pt2.txt (line 29)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.1->-r generative-models/requirements/pt2.txt (line 29)) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (3.0.0)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip@ git+https://github.com/openai/CLIP.git->-r generative-models/requirements/pt2.txt (line 3))\n",
            "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->-r generative-models/requirements/pt2.txt (line 27)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.6.0->-r generative-models/requirements/pt2.txt (line 7)) (1.3.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.13.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.73.1->-r generative-models/requirements/pt2.txt (line 23)) (0.1.2)\n",
            "Building wheels for collected packages: clip, fairscale, fire, antlr4-python3-runtime, pudb, lit, urwid_readline\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=2c072f158f37bf77151b802167043821ab0597cef110598b768935021dbe569c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tlne13ir/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332106 sha256=2cd22f0d6cee075abf6d5d098b2727dd8bc20768a5b37c834f7c17714e4b8c78\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116933 sha256=1ccd3aae44a7f7347b0d576eb8ea3ca6e873b120cbd47e1f2c807392f845a904\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=1eee83080efc8ad780e70af3adefd73ec9e6e113e3af337dd82eed56f707970d\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for pudb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pudb: filename=pudb-2023.1-py3-none-any.whl size=86116 sha256=41002589b66a415c50707280ca8698700493abd18b05261fa419ad58da5ff348\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/03/e9/97cb1ce91fb1601f85470b71f11fcd3c6617e81735ccd4460c\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=6ca28afba7ed564b488036f0f172f910fa0df0c1e9c475d5454219d0e3f502b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "  Building wheel for urwid_readline (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for urwid_readline: filename=urwid_readline-0.13-py3-none-any.whl size=7549 sha256=6b44bcda0743e405e6782fcc07fb51f097d7794b78747fc9fa0c994f43ec1f36\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/1d/d8/20c6d76afd5bd205f5f95f19640df9a4e88fc6f1a4c25bb693\n",
            "Successfully built clip fairscale fire antlr4-python3-runtime pudb lit urwid_readline\n",
            "Installing collected packages: wcwidth, tokenizers, sentencepiece, ninja, lit, braceexpand, antlr4-python3-runtime, watchdog, validators, urwid, urllib3, tzdata, smmap, setproctitle, pillow, pathspec, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, mypy-extensions, lightning-utilities, jedi, ftfy, fire, einops, docker-pycreds, chardet, webdataset, urwid_readline, tensorboardx, sentry-sdk, pydeck, pandas, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, gitdb, black, pudb, matplotlib, gitpython, wandb, transformers, streamlit, triton, torch, torchvision, torchmetrics, timm, xformers, torchdata, torchaudio, pytorch-lightning, open-clip-torch, kornia, invisible-watermark, fairscale, clip\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.10\n",
            "    Uninstalling wcwidth-0.2.10:\n",
            "      Successfully uninstalled wcwidth-0.2.10\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.8.0.76\n",
            "    Uninstalling opencv-python-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-4.8.0.76\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.0\n",
            "    Uninstalling torchdata-0.7.0:\n",
            "      Successfully uninstalled torchdata-0.7.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu118\n",
            "    Uninstalling torchaudio-2.1.0+cu118:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torchdata==0.7.0, but you have torchdata 0.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-23.7.0 braceexpand-0.1.7 chardet-5.1.0 clip-1.0 docker-pycreds-0.4.0 einops-0.7.0 fairscale-0.4.13 fire-0.5.0 ftfy-6.1.3 gitdb-4.0.11 gitpython-3.1.40 invisible-watermark-0.2.0 jedi-0.19.1 kornia-0.6.9 lightning-utilities-0.10.0 lit-17.0.5 matplotlib-3.8.2 mypy-extensions-1.0.0 ninja-1.11.1.1 numpy-1.26.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 open-clip-torch-2.23.0 opencv-python-4.6.0.66 pandas-2.1.3 pathspec-0.11.2 pillow-10.1.0 pudb-2023.1 pydeck-0.8.1b0 pytorch-lightning-2.0.1 sentencepiece-0.1.99 sentry-sdk-1.37.0 setproctitle-1.3.3 smmap-5.0.1 streamlit-1.28.2 tensorboardx-2.6 timm-0.9.11 tokenizers-0.12.1 torch-2.0.1 torchaudio-2.0.2 torchdata-0.6.1 torchmetrics-1.2.0 torchvision-0.15.2 transformers-4.19.1 triton-2.0.0 tzdata-2023.3 urllib3-1.26.18 urwid-2.2.3 urwid_readline-0.13 validators-0.22.0 wandb-0.16.0 watchdog-3.0.0 wcwidth-0.2.12 webdataset-0.2.79 xformers-0.0.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "pydevd_plugins",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3\n",
        "Install the Stable Video Diffusion library and download the official SVD-XT model from huggingface:\n",
        "\n",
        "https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt\n"
      ],
      "metadata": {
        "id": "YoYumpKELtAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd generative-models\n",
        "!pip install .\n",
        "!mkdir checkpoints\n",
        "!wget -O checkpoints/svd_xt.safetensors https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/resolve/main/svd_xt.safetensors?download=true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKqepP6b16G9",
        "outputId": "ba88b74a-0bc3-4fd1-e7c8-f0ee26de2a9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/generative-models\n",
            "Processing /content/generative-models\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sgm\n",
            "  Building wheel for sgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgm: filename=sgm-0.1.0-py3-none-any.whl size=116101 sha256=192a0a685559a6fb2da9c26b484d80c92fb54ac1b0d49472664ca3c185c4a2a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/9b/27/03142f4dee9fa0a99f6c146eae81eb66e17b781145ecb05fa5\n",
            "Successfully built sgm\n",
            "Installing collected packages: sgm\n",
            "Successfully installed sgm-0.1.0\n",
            "--2023-11-24 11:27:26--  https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/resolve/main/svd_xt.safetensors?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.38, 13.35.7.5, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/6e/59/6e594adc90884e0f59c5249f166a20166135ccab3a168d824ca8ef3bc5512e8c/b2652c23d64a1da5f14d55011b9b6dce55f2e72e395719f1cd1f8a079b00a451?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27svd_xt.safetensors%3B+filename%3D%22svd_xt.safetensors%22%3B&Expires=1701084447&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTA4NDQ0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzZlLzU5LzZlNTk0YWRjOTA4ODRlMGY1OWM1MjQ5ZjE2NmEyMDE2NjEzNWNjYWIzYTE2OGQ4MjRjYThlZjNiYzU1MTJlOGMvYjI2NTJjMjNkNjRhMWRhNWYxNGQ1NTAxMWI5YjZkY2U1NWYyZTcyZTM5NTcxOWYxY2QxZjhhMDc5YjAwYTQ1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IQZ9xnluQqqkrIZCXejROJQaSlwmWSSyWfjvSrbop0dLEUrhkKctfsKT3pli4%7EWFS30bTC9HG-g-XS1aDfwj8np8xyHq7srl0ULrjdw6dZ6b-eVJReHByG1lhszzdZKggMAdjyPc-aPOhL67enInmN-UuM9biR0nZsENNdiH-o1bx-JQKmdYnE9BgiX2X8nnoSYn1DyZG7C5HEX7GEqdRKAd35URgWaxzXhm%7EUO5xRDq5MIRd8yixAst%7EqWo72XJy1am%7EksJz84lUwF%7E%7EMuBOoyTBD6qqqU-Z-FTtxsQ20%7EOFmm08CQ24ZdwYZOZtdkqrwSq9%7Eemu19vAUrXTg14jQ__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
            "--2023-11-24 11:27:27--  https://cdn-lfs-us-1.huggingface.co/repos/6e/59/6e594adc90884e0f59c5249f166a20166135ccab3a168d824ca8ef3bc5512e8c/b2652c23d64a1da5f14d55011b9b6dce55f2e72e395719f1cd1f8a079b00a451?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27svd_xt.safetensors%3B+filename%3D%22svd_xt.safetensors%22%3B&Expires=1701084447&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTA4NDQ0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzZlLzU5LzZlNTk0YWRjOTA4ODRlMGY1OWM1MjQ5ZjE2NmEyMDE2NjEzNWNjYWIzYTE2OGQ4MjRjYThlZjNiYzU1MTJlOGMvYjI2NTJjMjNkNjRhMWRhNWYxNGQ1NTAxMWI5YjZkY2U1NWYyZTcyZTM5NTcxOWYxY2QxZjhhMDc5YjAwYTQ1MT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=IQZ9xnluQqqkrIZCXejROJQaSlwmWSSyWfjvSrbop0dLEUrhkKctfsKT3pli4%7EWFS30bTC9HG-g-XS1aDfwj8np8xyHq7srl0ULrjdw6dZ6b-eVJReHByG1lhszzdZKggMAdjyPc-aPOhL67enInmN-UuM9biR0nZsENNdiH-o1bx-JQKmdYnE9BgiX2X8nnoSYn1DyZG7C5HEX7GEqdRKAd35URgWaxzXhm%7EUO5xRDq5MIRd8yixAst%7EqWo72XJy1am%7EksJz84lUwF%7E%7EMuBOoyTBD6qqqU-Z-FTtxsQ20%7EOFmm08CQ24ZdwYZOZtdkqrwSq9%7Eemu19vAUrXTg14jQ__&Key-Pair-Id=KCD77M1F0VK2B\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.35.35.127, 13.35.35.125, 13.35.35.21, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.35.35.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9559625980 (8.9G) [binary/octet-stream]\n",
            "Saving to: ‘checkpoints/svd_xt.safetensors’\n",
            "\n",
            "checkpoints/svd_xt. 100%[===================>]   8.90G  25.0MB/s    in 6m 10s  \n",
            "\n",
            "2023-11-24 11:33:37 (24.7 MB/s) - ‘checkpoints/svd_xt.safetensors’ saved [9559625980/9559625980]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4\n",
        "Just the main code block."
      ],
      "metadata": {
        "id": "sRQcJw63N_8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from einops import rearrange, repeat\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from sgm.inference.helpers import embed_watermark\n",
        "from sgm.util import default, instantiate_from_config\n",
        "from scripts.util.detection.nsfw_and_watermark_dectection import DeepFloydDataFiltering\n",
        "\n",
        "def sample(\n",
        "    input_path: str = \"assets/test_image.png\",  # Can either be image file or folder with image files\n",
        "    num_frames: Optional[int] = None,\n",
        "    num_steps: Optional[int] = None,\n",
        "    version: str = \"svd\",\n",
        "    fps_id: int = 6,\n",
        "    motion_bucket_id: int = 127,\n",
        "    cond_aug: float = 0.02,\n",
        "    seed: int = 23,\n",
        "    decoding_t: int = 6,  # Number of frames decoded at a time! This eats most VRAM. Reduce if necessary.\n",
        "    device: str = \"cuda\",\n",
        "    output_folder: Optional[str] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simple script to generate a single sample conditioned on an image `input_path` or multiple images, one for each\n",
        "    image file in folder `input_path`. If you run out of VRAM, try decreasing `decoding_t`.\n",
        "    \"\"\"\n",
        "\n",
        "    if version == \"svd\":\n",
        "        num_frames = default(num_frames, 14)\n",
        "        num_steps = default(num_steps, 25)\n",
        "        output_folder = default(output_folder, \"outputs/simple_video_sample/svd/\")\n",
        "        model_config = \"scripts/sampling/configs/svd.yaml\"\n",
        "    elif version == \"svd_xt\":\n",
        "        num_frames = default(num_frames, 25)\n",
        "        num_steps = default(num_steps, 30)\n",
        "        output_folder = default(output_folder, \"outputs/simple_video_sample/svd_xt/\")\n",
        "        model_config = \"scripts/sampling/configs/svd_xt.yaml\"\n",
        "    elif version == \"svd_image_decoder\":\n",
        "        num_frames = default(num_frames, 14)\n",
        "        num_steps = default(num_steps, 25)\n",
        "        output_folder = default(\n",
        "            output_folder, \"outputs/simple_video_sample/svd_image_decoder/\"\n",
        "        )\n",
        "        model_config = \"scripts/sampling/configs/svd_image_decoder.yaml\"\n",
        "    elif version == \"svd_xt_image_decoder\":\n",
        "        num_frames = default(num_frames, 25)\n",
        "        num_steps = default(num_steps, 30)\n",
        "        output_folder = default(\n",
        "            output_folder, \"outputs/simple_video_sample/svd_xt_image_decoder/\"\n",
        "        )\n",
        "        model_config = \"scripts/sampling/configs/svd_xt_image_decoder.yaml\"\n",
        "    else:\n",
        "        raise ValueError(f\"Version {version} does not exist.\")\n",
        "\n",
        "    model, filter = load_model(\n",
        "        model_config,\n",
        "        device,\n",
        "        num_frames,\n",
        "        num_steps,\n",
        "    )\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    path = Path(input_path)\n",
        "    all_img_paths = []\n",
        "    if path.is_file():\n",
        "        if any([input_path.endswith(x) for x in [\"jpg\", \"jpeg\", \"png\"]]):\n",
        "            all_img_paths = [input_path]\n",
        "        else:\n",
        "            raise ValueError(\"Path is not valid image file.\")\n",
        "    elif path.is_dir():\n",
        "        all_img_paths = sorted(\n",
        "            [\n",
        "                f\n",
        "                for f in path.iterdir()\n",
        "                if f.is_file() and f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]\n",
        "            ]\n",
        "        )\n",
        "        if len(all_img_paths) == 0:\n",
        "            raise ValueError(\"Folder does not contain any images.\")\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    for input_img_path in all_img_paths:\n",
        "        with Image.open(input_img_path) as image:\n",
        "            if image.mode == \"RGBA\":\n",
        "                image = image.convert(\"RGB\")\n",
        "            w, h = image.size\n",
        "\n",
        "            if h % 64 != 0 or w % 64 != 0:\n",
        "                width, height = map(lambda x: x - x % 64, (w, h))\n",
        "                image = image.resize((width, height))\n",
        "                print(\n",
        "                    f\"WARNING: Your image is of size {h}x{w} which is not divisible by 64. We are resizing to {height}x{width}!\"\n",
        "                )\n",
        "\n",
        "            image = ToTensor()(image)\n",
        "            image = image * 2.0 - 1.0\n",
        "\n",
        "        image = image.unsqueeze(0).to(device).half()\n",
        "        H, W = image.shape[2:]\n",
        "        assert image.shape[1] == 3\n",
        "        F = 8\n",
        "        C = 4\n",
        "        shape = (num_frames, C, H // F, W // F)\n",
        "        if (H, W) != (576, 1024):\n",
        "            print(\n",
        "                \"WARNING: The conditioning frame you provided is not 576x1024. This leads to suboptimal performance as model was only trained on 576x1024. Consider increasing `cond_aug`.\"\n",
        "            )\n",
        "        if motion_bucket_id > 255:\n",
        "            print(\n",
        "                \"WARNING: High motion bucket! This may lead to suboptimal performance.\"\n",
        "            )\n",
        "\n",
        "        if fps_id < 5:\n",
        "            print(\"WARNING: Small fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        if fps_id > 30:\n",
        "            print(\"WARNING: Large fps value! This may lead to suboptimal performance.\")\n",
        "\n",
        "        value_dict = {}\n",
        "        value_dict[\"motion_bucket_id\"] = motion_bucket_id\n",
        "        value_dict[\"fps_id\"] = fps_id\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "        value_dict[\"cond_frames_without_noise\"] = image\n",
        "        value_dict[\"cond_frames\"] = image + cond_aug * torch.randn_like(image)\n",
        "        value_dict[\"cond_aug\"] = cond_aug\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch, batch_uc = get_batch(\n",
        "                get_unique_embedder_keys_from_conditioner(model.conditioner),\n",
        "                value_dict,\n",
        "                [1, num_frames],\n",
        "                T=num_frames,\n",
        "                device=device,\n",
        "            )\n",
        "            c, uc = model.conditioner.get_unconditional_conditioning(\n",
        "                batch,\n",
        "                batch_uc=batch_uc,\n",
        "                force_uc_zero_embeddings=[\n",
        "                    \"cond_frames\",\n",
        "                    \"cond_frames_without_noise\",\n",
        "                ],\n",
        "            )\n",
        "\n",
        "            for k in [\"crossattn\", \"concat\"]:\n",
        "                uc[k] = repeat(uc[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                uc[k] = rearrange(uc[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "                c[k] = repeat(c[k], \"b ... -> b t ...\", t=num_frames)\n",
        "                c[k] = rearrange(c[k], \"b t ... -> (b t) ...\", t=num_frames)\n",
        "\n",
        "            randn = torch.randn(shape, device=device).half()\n",
        "\n",
        "            additional_model_inputs = {}\n",
        "            additional_model_inputs[\"image_only_indicator\"] = torch.zeros(\n",
        "                2, num_frames\n",
        "            ).to(device).half()\n",
        "            additional_model_inputs[\"num_video_frames\"] = batch[\"num_video_frames\"]\n",
        "\n",
        "            def denoiser(input, sigma, c):\n",
        "                return model.denoiser(\n",
        "                    model.model, input, sigma, c, **additional_model_inputs\n",
        "                )\n",
        "\n",
        "            samples_z = model.sampler(denoiser, randn, cond=c, uc=uc)\n",
        "            model.en_and_decode_n_samples_a_time = decoding_t\n",
        "            samples_x = model.decode_first_stage(samples_z)\n",
        "            samples = torch.clamp((samples_x + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "            base_count = len(glob(os.path.join(output_folder, \"*.mp4\")))\n",
        "            video_path = os.path.join(output_folder, f\"{base_count:06d}.mp4\")\n",
        "            writer = cv2.VideoWriter(\n",
        "                video_path,\n",
        "                cv2.VideoWriter_fourcc(*\"MP4V\"),\n",
        "                fps_id + 1,\n",
        "                (samples.shape[-1], samples.shape[-2]),\n",
        "            )\n",
        "\n",
        "            samples = embed_watermark(samples.float())\n",
        "            samples = filter(samples)\n",
        "            vid = (\n",
        "                (rearrange(samples, \"t c h w -> t h w c\") * 255)\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "                .astype(np.uint8)\n",
        "            )\n",
        "            for frame in vid:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "                writer.write(frame)\n",
        "            writer.release()\n",
        "\n",
        "def get_unique_embedder_keys_from_conditioner(conditioner):\n",
        "    return list(set([x.input_key for x in conditioner.embedders]))\n",
        "\n",
        "\n",
        "def get_batch(keys, value_dict, N, T, device):\n",
        "    batch = {}\n",
        "    batch_uc = {}\n",
        "\n",
        "    for key in keys:\n",
        "        if key == \"fps_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"fps_id\"]])\n",
        "                .to(device)\n",
        "                .half()\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"motion_bucket_id\":\n",
        "            batch[key] = (\n",
        "                torch.tensor([value_dict[\"motion_bucket_id\"]])\n",
        "                .to(device)\n",
        "                .half()\n",
        "                .repeat(int(math.prod(N)))\n",
        "            )\n",
        "        elif key == \"cond_aug\":\n",
        "            batch[key] = repeat(\n",
        "                torch.tensor([value_dict[\"cond_aug\"]]).to(device).half(),\n",
        "                \"1 -> b\",\n",
        "                b=math.prod(N),\n",
        "            )\n",
        "        elif key == \"cond_frames\":\n",
        "            batch[key] = repeat(value_dict[\"cond_frames\"].half(), \"1 ... -> b ...\", b=N[0])\n",
        "        elif key == \"cond_frames_without_noise\":\n",
        "            batch[key] = repeat(\n",
        "                value_dict[\"cond_frames_without_noise\"].half(), \"1 ... -> b ...\", b=N[0]\n",
        "            )\n",
        "        else:\n",
        "            batch[key] = value_dict[key].half()\n",
        "\n",
        "    if T is not None:\n",
        "        batch[\"num_video_frames\"] = T\n",
        "\n",
        "    for key in batch.keys():\n",
        "        if key not in batch_uc and isinstance(batch[key], torch.Tensor):\n",
        "            batch_uc[key] = torch.clone(batch[key])\n",
        "\n",
        "    return batch, batch_uc\n",
        "\n",
        "\n",
        "def load_model(\n",
        "    config: str,\n",
        "    device: str,\n",
        "    num_frames: int,\n",
        "    num_steps: int,\n",
        "):\n",
        "    config = OmegaConf.load(config)\n",
        "    if device == \"cuda\":\n",
        "        config.model.params.conditioner_config.params.emb_models[0].params.open_clip_embedding_config.params.init_device = device\n",
        "\n",
        "    config.model.params.sampler_config.params.num_steps = num_steps\n",
        "    config.model.params.sampler_config.params.guider_config.params.num_frames = (num_frames)\n",
        "    if device == \"cuda\":\n",
        "        with torch.device(device):\n",
        "            model = instantiate_from_config(config.model).to(device).half().eval()\n",
        "    else:\n",
        "        model = instantiate_from_config(config.model).to(device).half().eval()\n",
        "\n",
        "    filter = DeepFloydDataFiltering(verbose=False, device=device)\n",
        "    model = model.half()\n",
        "    return model, filter\n"
      ],
      "metadata": {
        "id": "rQuglJ6pz23C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5\n",
        "Here comes the fun part! Hit that play button to kickstart the video magic. 🍿🚀\n",
        "- Change the 'input_path' to specify your initial image.\n",
        "- Adjust the 'seed' to generate variations.\n",
        "- By default, the output video will be created in the \"generative-models\" folder.\n",
        "- The generation process may take approximately 10 minutes on an Nvidia Tesla T4 GPU.\n"
      ],
      "metadata": {
        "id": "rFTzktM5OG8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "sample(\n",
        "    input_path = \"assets/test_image.png\",\n",
        "    num_frames = 25,\n",
        "    num_steps = None,\n",
        "    version = \"svd_xt\",\n",
        "    fps_id = 6,\n",
        "    motion_bucket_id = 127,\n",
        "    cond_aug = 0.02,\n",
        "    seed = 23,\n",
        "    decoding_t = 6,\n",
        "    device = \"cuda\",\n",
        "    output_folder = \".\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XejqoJId1uiE",
        "outputId": "a2d37a5e-3e45-4e25-95bd-48a594bbb087"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n",
            "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
            "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
            "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Restored from checkpoints/svd_xt.safetensors with 0 missing and 0 unexpected keys\n",
            "CPU times: user 7min 40s, sys: 16.1 s, total: 7min 56s\n",
            "Wall time: 9min 16s\n"
          ]
        }
      ]
    }
  ]
}